{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest, RFECV, mutual_info_classif, mutual_info_regression, SelectPercentile\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import seaborn as sn\n",
    "from sympy import fft \n",
    "#import keras\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, BatchNormalization, Dropout\n",
    "#from keras import regularizers\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Introduce the Data¶\n",
    "\n",
    "Task: Given EEG series, predict wheiter they have Epileptic-Seizure or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X21.V1.791</td>\n",
       "      <td>135</td>\n",
       "      <td>190</td>\n",
       "      <td>229</td>\n",
       "      <td>223</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>-9</td>\n",
       "      <td>-33</td>\n",
       "      <td>...</td>\n",
       "      <td>-17</td>\n",
       "      <td>-15</td>\n",
       "      <td>-31</td>\n",
       "      <td>-77</td>\n",
       "      <td>-103</td>\n",
       "      <td>-127</td>\n",
       "      <td>-116</td>\n",
       "      <td>-83</td>\n",
       "      <td>-51</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X15.V1.924</td>\n",
       "      <td>386</td>\n",
       "      <td>382</td>\n",
       "      <td>356</td>\n",
       "      <td>331</td>\n",
       "      <td>320</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>272</td>\n",
       "      <td>244</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>150</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>143</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X8.V1.1</td>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-37</td>\n",
       "      <td>-32</td>\n",
       "      <td>-36</td>\n",
       "      <td>-57</td>\n",
       "      <td>-73</td>\n",
       "      <td>-85</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>-12</td>\n",
       "      <td>-30</td>\n",
       "      <td>-35</td>\n",
       "      <td>-35</td>\n",
       "      <td>-36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X16.V1.60</td>\n",
       "      <td>-105</td>\n",
       "      <td>-101</td>\n",
       "      <td>-96</td>\n",
       "      <td>-92</td>\n",
       "      <td>-89</td>\n",
       "      <td>-95</td>\n",
       "      <td>-102</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>...</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>-80</td>\n",
       "      <td>-77</td>\n",
       "      <td>-85</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-69</td>\n",
       "      <td>-65</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X20.V1.54</td>\n",
       "      <td>-9</td>\n",
       "      <td>-65</td>\n",
       "      <td>-98</td>\n",
       "      <td>-102</td>\n",
       "      <td>-78</td>\n",
       "      <td>-48</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-12</td>\n",
       "      <td>-32</td>\n",
       "      <td>-41</td>\n",
       "      <td>-65</td>\n",
       "      <td>-83</td>\n",
       "      <td>-89</td>\n",
       "      <td>-73</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   X1   X2   X3   X4   X5   X6   X7   X8   X9  ...  X170  X171  \\\n",
       "0  X21.V1.791  135  190  229  223  192  125   55   -9  -33  ...   -17   -15   \n",
       "1  X15.V1.924  386  382  356  331  320  315  307  272  244  ...   164   150   \n",
       "2     X8.V1.1  -32  -39  -47  -37  -32  -36  -57  -73  -85  ...    57    64   \n",
       "3   X16.V1.60 -105 -101  -96  -92  -89  -95 -102 -100  -87  ...   -82   -81   \n",
       "4   X20.V1.54   -9  -65  -98 -102  -78  -48  -16    0  -21  ...     4     2   \n",
       "\n",
       "   X172  X173  X174  X175  X176  X177  X178  y  \n",
       "0   -31   -77  -103  -127  -116   -83   -51  4  \n",
       "1   146   152   157   156   154   143   129  1  \n",
       "2    48    19   -12   -30   -35   -35   -36  5  \n",
       "3   -80   -77   -85   -77   -72   -69   -65  5  \n",
       "4   -12   -32   -41   -65   -83   -89   -73  5  \n",
       "\n",
       "[5 rows x 180 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X21.V1.791</td>\n",
       "      <td>135</td>\n",
       "      <td>190</td>\n",
       "      <td>229</td>\n",
       "      <td>223</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>-9</td>\n",
       "      <td>-33</td>\n",
       "      <td>...</td>\n",
       "      <td>-17</td>\n",
       "      <td>-15</td>\n",
       "      <td>-31</td>\n",
       "      <td>-77</td>\n",
       "      <td>-103</td>\n",
       "      <td>-127</td>\n",
       "      <td>-116</td>\n",
       "      <td>-83</td>\n",
       "      <td>-51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X15.V1.924</td>\n",
       "      <td>386</td>\n",
       "      <td>382</td>\n",
       "      <td>356</td>\n",
       "      <td>331</td>\n",
       "      <td>320</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>272</td>\n",
       "      <td>244</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>150</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>143</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X8.V1.1</td>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-37</td>\n",
       "      <td>-32</td>\n",
       "      <td>-36</td>\n",
       "      <td>-57</td>\n",
       "      <td>-73</td>\n",
       "      <td>-85</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>-12</td>\n",
       "      <td>-30</td>\n",
       "      <td>-35</td>\n",
       "      <td>-35</td>\n",
       "      <td>-36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X16.V1.60</td>\n",
       "      <td>-105</td>\n",
       "      <td>-101</td>\n",
       "      <td>-96</td>\n",
       "      <td>-92</td>\n",
       "      <td>-89</td>\n",
       "      <td>-95</td>\n",
       "      <td>-102</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>...</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>-80</td>\n",
       "      <td>-77</td>\n",
       "      <td>-85</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-69</td>\n",
       "      <td>-65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X20.V1.54</td>\n",
       "      <td>-9</td>\n",
       "      <td>-65</td>\n",
       "      <td>-98</td>\n",
       "      <td>-102</td>\n",
       "      <td>-78</td>\n",
       "      <td>-48</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-12</td>\n",
       "      <td>-32</td>\n",
       "      <td>-41</td>\n",
       "      <td>-65</td>\n",
       "      <td>-83</td>\n",
       "      <td>-89</td>\n",
       "      <td>-73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   X1   X2   X3   X4   X5   X6   X7   X8   X9  ...  X170  X171  \\\n",
       "0  X21.V1.791  135  190  229  223  192  125   55   -9  -33  ...   -17   -15   \n",
       "1  X15.V1.924  386  382  356  331  320  315  307  272  244  ...   164   150   \n",
       "2     X8.V1.1  -32  -39  -47  -37  -32  -36  -57  -73  -85  ...    57    64   \n",
       "3   X16.V1.60 -105 -101  -96  -92  -89  -95 -102 -100  -87  ...   -82   -81   \n",
       "4   X20.V1.54   -9  -65  -98 -102  -78  -48  -16    0  -21  ...     4     2   \n",
       "\n",
       "   X172  X173  X174  X175  X176  X177  X178  y  \n",
       "0   -31   -77  -103  -127  -116   -83   -51  0  \n",
       "1   146   152   157   156   154   143   129  1  \n",
       "2    48    19   -12   -30   -35   -35   -36  0  \n",
       "3   -80   -77   -85   -77   -72   -69   -65  0  \n",
       "4   -12   -32   -41   -65   -83   -89   -73  0  \n",
       "\n",
       "[5 rows x 180 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = df.columns\n",
    "outcome = df.y\n",
    "outcome[outcome>1]=0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of trials for the non-seizure class is: 9200\n",
      "The number of trials for the seizure class is: 2300\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sn.countplot(outcome,label=\"Count\")\n",
    "non_seizure, seizure = outcome.value_counts()\n",
    "print('The number of trials for the non-seizure class is:', non_seizure)\n",
    "print('The number of trials for the seizure class is:', seizure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11500, 178)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,1:179].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:,179].values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic data cleaning\n",
    "A. Dealing with data types\n",
    "\n",
    "    -Numeric, e.g. income, age\n",
    "    -Categorical, e.g. gender, nationality\n",
    "    -Ordinal, e.g. low/medium/high\n",
    "    \n",
    "-Models can only handle numeric features\n",
    "\n",
    "-Must convert categorical and ordinal features into numeric features\n",
    "\n",
    "    -Create dummy features\n",
    "    -Transform a categorical feature into a set of dummy features, each representing a unique category\n",
    "    -In the set of dummy features, 1 indicates that the observation belongs to that category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "B. Handling missing data\n",
    "-Models can not handle missing data\n",
    "\n",
    "-Simplest solution\n",
    "\n",
    "    Remove observations/features that have missing data\n",
    "-But, removing missing data can introduce a lot of issues\n",
    "\n",
    "    Data is randomly missing: potentially lose a lot of your data\n",
    "    Data is non-randomly missing: in addition to losing data, you are also introducing potential biases\n",
    "    Usually, this is a poor solution\n",
    "\n",
    "-An alternative solution is to use imputation\n",
    "    \n",
    "    Replace missing value with another value\n",
    "    Strategies: mean, median, highest frequency value of given feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Distribution of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Interactions amongst features¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Dimensionality reduction using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature election and model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Build model using processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model using unprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classificadores\n",
    "modelos = []\n",
    "modelos.append(('Logistic Regression', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "modelos.append(('Linear Discriminant Analysis', LinearDiscriminantAnalysis()))\n",
    "modelos.append(('K-Nearest Neighbors', KNeighborsClassifier()))\n",
    "modelos.append(('Classification and Regression Trees', DecisionTreeClassifier()))\n",
    "modelos.append(('Gaussian Naive Bayes', GaussianNB()))\n",
    "modelos.append(('Linear Support Vector Machines', svm.LinearSVC()))\n",
    "modelos.append(('Extra Trees Classifier',ExtraTreesClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.826087 (0.003557)\n",
      "Linear Discriminant Analysis: 0.823230 (0.004781)\n",
      "K-Nearest Neighbors: 0.920373 (0.005540)\n",
      "Classification and Regression Trees: 0.938385 (0.008857)\n",
      "Gaussian Naive Bayes: 0.958137 (0.007936)\n",
      "Linear Support Vector Machines: 0.838012 (0.006809)\n",
      "Extra Trees Classifier: 0.973540 (0.003687)\n"
     ]
    }
   ],
   "source": [
    "resultados = []\n",
    "nomes = []\n",
    "for nome, modelo in modelos:\n",
    "\tresultado_validacao_cruzada = cross_val_score(modelo, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "\tresultados.append(resultado_validacao_cruzada)\n",
    "\tnomes.append(nome)\n",
    "\tprint('%s: %f (%f)' % (nome, resultado_validacao_cruzada.mean(), resultado_validacao_cruzada.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(resultados)\n",
    "plt.title('Comparação de Algoritmos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicao = []\n",
    "for nome, modelo in modelos:\n",
    "    modelo.fit(X_train,y_train)\n",
    "    predicao.append(modelo.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "0.8269565217391305\n",
      "[[2738   17]\n",
      " [ 580  115]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90      2755\n",
      "           1       0.87      0.17      0.28       695\n",
      "\n",
      "    accuracy                           0.83      3450\n",
      "   macro avg       0.85      0.58      0.59      3450\n",
      "weighted avg       0.83      0.83      0.78      3450\n",
      "\n",
      "Linear Discriminant Analysis\n",
      "0.827536231884058\n",
      "[[2747    8]\n",
      " [ 587  108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90      2755\n",
      "           1       0.93      0.16      0.27       695\n",
      "\n",
      "    accuracy                           0.83      3450\n",
      "   macro avg       0.88      0.58      0.58      3450\n",
      "weighted avg       0.85      0.83      0.77      3450\n",
      "\n",
      "K-Nearest Neighbors\n",
      "0.9156521739130434\n",
      "[[2748    7]\n",
      " [ 284  411]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      2755\n",
      "           1       0.98      0.59      0.74       695\n",
      "\n",
      "    accuracy                           0.92      3450\n",
      "   macro avg       0.94      0.79      0.84      3450\n",
      "weighted avg       0.92      0.92      0.91      3450\n",
      "\n",
      "Classification and Regression Trees\n",
      "0.9388405797101449\n",
      "[[2659   96]\n",
      " [ 115  580]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      2755\n",
      "           1       0.86      0.83      0.85       695\n",
      "\n",
      "    accuracy                           0.94      3450\n",
      "   macro avg       0.91      0.90      0.90      3450\n",
      "weighted avg       0.94      0.94      0.94      3450\n",
      "\n",
      "Gaussian Naive Bayes\n",
      "0.956231884057971\n",
      "[[2685   70]\n",
      " [  81  614]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      2755\n",
      "           1       0.90      0.88      0.89       695\n",
      "\n",
      "    accuracy                           0.96      3450\n",
      "   macro avg       0.93      0.93      0.93      3450\n",
      "weighted avg       0.96      0.96      0.96      3450\n",
      "\n",
      "Linear Support Vector Machines\n",
      "0.8385507246376812\n",
      "[[2753    2]\n",
      " [ 555  140]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91      2755\n",
      "           1       0.99      0.20      0.33       695\n",
      "\n",
      "    accuracy                           0.84      3450\n",
      "   macro avg       0.91      0.60      0.62      3450\n",
      "weighted avg       0.86      0.84      0.79      3450\n",
      "\n",
      "Extra Trees Classifier\n",
      "0.9698550724637681\n",
      "[[2732   23]\n",
      " [  81  614]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      2755\n",
      "           1       0.96      0.88      0.92       695\n",
      "\n",
      "    accuracy                           0.97      3450\n",
      "   macro avg       0.97      0.94      0.95      3450\n",
      "weighted avg       0.97      0.97      0.97      3450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predicao)):\n",
    "    print(nomes[i])\n",
    "    print(accuracy_score(y_test,predicao[i]))\n",
    "    print(confusion_matrix(y_test,predicao[i]))\n",
    "    print(classification_report(y_test,predicao[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
